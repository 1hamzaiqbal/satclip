{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SatCLIP Effective Resolution Testing\n",
    "\n",
    "This notebook tests the setup and compares L=10 vs L=40 SatCLIP models.\n",
    "\n",
    "**Goal**: Verify we can load models and begin investigating effective spatial resolution.\n",
    "\n",
    "For better performance, go to `Runtime -> Change runtime type` and select `T4 GPU`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone SatCLIP repository (run this in Colab)\n",
    "!rm -rf sample_data .config satclip 2>/dev/null\n",
    "!git clone https://github.com/1hamzaiqbal/satclip.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install lightning --quiet\n",
    "!pip install rasterio --quiet\n",
    "!pip install torchgeo --quiet\n",
    "!pip install huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./satclip/satclip')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import hf_hub_download\n",
    "from load import get_satclip\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Both L=10 and L=40 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load L=10 model (lower resolution)\n",
    "print(\"Loading L=10 model...\")\n",
    "model_l10 = get_satclip(\n",
    "    hf_hub_download(\"microsoft/SatCLIP-ViT16-L10\", \"satclip-vit16-l10.ckpt\"),\n",
    "    device=device,\n",
    ")\n",
    "model_l10.eval()\n",
    "print(\"L=10 model loaded!\")\n",
    "\n",
    "# Load L=40 model (higher resolution)\n",
    "print(\"\\nLoading L=40 model...\")\n",
    "model_l40 = get_satclip(\n",
    "    hf_hub_download(\"microsoft/SatCLIP-ViT16-L40\", \"satclip-vit16-l40.ckpt\"),\n",
    "    device=device,\n",
    ")\n",
    "model_l40.eval()\n",
    "print(\"L=40 model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect model architecture\n",
    "print(\"L=10 Location Encoder:\")\n",
    "print(model_l10)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"L=40 Location Encoder:\")\n",
    "print(model_l40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Basic Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with some well-known locations\n",
    "test_locations = torch.tensor([\n",
    "    [-122.4194, 37.7749],   # San Francisco\n",
    "    [-74.0060, 40.7128],    # New York\n",
    "    [0.1276, 51.5074],      # London\n",
    "    [139.6917, 35.6895],    # Tokyo\n",
    "    [77.2090, 28.6139],     # Delhi\n",
    "    [-43.1729, -22.9068],   # Rio de Janeiro\n",
    "]).double()\n",
    "\n",
    "location_names = ['San Francisco', 'New York', 'London', 'Tokyo', 'Delhi', 'Rio de Janeiro']\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb_l10 = model_l10(test_locations.to(device)).cpu()\n",
    "    emb_l40 = model_l40(test_locations.to(device)).cpu()\n",
    "\n",
    "print(f\"L=10 embeddings shape: {emb_l10.shape}\")\n",
    "print(f\"L=40 embeddings shape: {emb_l40.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding Similarity Analysis\n",
    "\n",
    "Compare how similar the embeddings are between locations for L=10 vs L=40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(embeddings):\n",
    "    \"\"\"Compute pairwise cosine similarity matrix.\"\"\"\n",
    "    # Normalize embeddings\n",
    "    norm_emb = F.normalize(embeddings, p=2, dim=1)\n",
    "    # Compute similarity matrix\n",
    "    sim_matrix = torch.mm(norm_emb, norm_emb.t())\n",
    "    return sim_matrix.numpy()\n",
    "\n",
    "sim_l10 = compute_similarity_matrix(emb_l10.float())\n",
    "sim_l40 = compute_similarity_matrix(emb_l40.float())\n",
    "\n",
    "# Plot similarity matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "im1 = axes[0].imshow(sim_l10, cmap='RdYlBu_r', vmin=-1, vmax=1)\n",
    "axes[0].set_title('L=10 Embedding Similarity')\n",
    "axes[0].set_xticks(range(len(location_names)))\n",
    "axes[0].set_yticks(range(len(location_names)))\n",
    "axes[0].set_xticklabels(location_names, rotation=45, ha='right')\n",
    "axes[0].set_yticklabels(location_names)\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(sim_l40, cmap='RdYlBu_r', vmin=-1, vmax=1)\n",
    "axes[1].set_title('L=40 Embedding Similarity')\n",
    "axes[1].set_xticks(range(len(location_names)))\n",
    "axes[1].set_yticks(range(len(location_names)))\n",
    "axes[1].set_xticklabels(location_names, rotation=45, ha='right')\n",
    "axes[1].set_yticklabels(location_names)\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distance-Based Resolution Test\n",
    "\n",
    "Key question: At what distance do embeddings start to differ significantly?\n",
    "\n",
    "We'll generate points at varying distances from a reference and measure similarity decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"Calculate the great circle distance in kilometers.\"\"\"\n",
    "    R = 6371  # Earth's radius in km\n",
    "    \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def generate_points_at_distances(ref_lon, ref_lat, distances_km, n_samples=8):\n",
    "    \"\"\"\n",
    "    Generate points at specified distances from reference in different directions.\n",
    "    Returns (N_distances, n_samples, 2) array of [lon, lat] coordinates.\n",
    "    \"\"\"\n",
    "    R = 6371  # Earth's radius in km\n",
    "    points = []\n",
    "    \n",
    "    for dist in distances_km:\n",
    "        dist_points = []\n",
    "        for i in range(n_samples):\n",
    "            bearing = 2 * np.pi * i / n_samples  # Evenly spaced bearings\n",
    "            \n",
    "            # Calculate new point using spherical geometry\n",
    "            lat1 = np.radians(ref_lat)\n",
    "            lon1 = np.radians(ref_lon)\n",
    "            d = dist / R\n",
    "            \n",
    "            lat2 = np.arcsin(np.sin(lat1) * np.cos(d) + \n",
    "                           np.cos(lat1) * np.sin(d) * np.cos(bearing))\n",
    "            lon2 = lon1 + np.arctan2(np.sin(bearing) * np.sin(d) * np.cos(lat1),\n",
    "                                     np.cos(d) - np.sin(lat1) * np.sin(lat2))\n",
    "            \n",
    "            dist_points.append([np.degrees(lon2), np.degrees(lat2)])\n",
    "        points.append(dist_points)\n",
    "    \n",
    "    return np.array(points)\n",
    "\n",
    "# Test with San Francisco as reference\n",
    "ref_lon, ref_lat = -122.4194, 37.7749\n",
    "\n",
    "# Distances to test (in km) - logarithmic scale from 1km to 10000km\n",
    "distances = [1, 5, 10, 50, 100, 500, 1000, 5000]\n",
    "\n",
    "points = generate_points_at_distances(ref_lon, ref_lat, distances, n_samples=8)\n",
    "print(f\"Generated points shape: {points.shape}\")  # (n_distances, n_samples, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings for reference and all distance points\n",
    "ref_coord = torch.tensor([[ref_lon, ref_lat]]).double()\n",
    "\n",
    "with torch.no_grad():\n",
    "    ref_emb_l10 = model_l10(ref_coord.to(device)).cpu()\n",
    "    ref_emb_l40 = model_l40(ref_coord.to(device)).cpu()\n",
    "\n",
    "# Compute similarities at each distance\n",
    "sims_l10 = []\n",
    "sims_l40 = []\n",
    "\n",
    "for i, dist in enumerate(distances):\n",
    "    dist_coords = torch.tensor(points[i]).double()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        emb_l10 = model_l10(dist_coords.to(device)).cpu()\n",
    "        emb_l40 = model_l40(dist_coords.to(device)).cpu()\n",
    "    \n",
    "    # Compute cosine similarity with reference\n",
    "    sim_l10 = F.cosine_similarity(ref_emb_l10.float(), emb_l10.float()).mean().item()\n",
    "    sim_l40 = F.cosine_similarity(ref_emb_l40.float(), emb_l40.float()).mean().item()\n",
    "    \n",
    "    sims_l10.append(sim_l10)\n",
    "    sims_l40.append(sim_l40)\n",
    "    \n",
    "    print(f\"Distance: {dist:5d} km | L=10 similarity: {sim_l10:.4f} | L=40 similarity: {sim_l40:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot similarity vs distance\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.semilogx(distances, sims_l10, 'o-', label='L=10 (low resolution)', linewidth=2, markersize=8)\n",
    "plt.semilogx(distances, sims_l40, 's-', label='L=40 (high resolution)', linewidth=2, markersize=8)\n",
    "\n",
    "plt.xlabel('Distance from reference (km)', fontsize=12)\n",
    "plt.ylabel('Cosine Similarity', fontsize=12)\n",
    "plt.title('Embedding Similarity vs Distance\\n(How quickly do embeddings change with distance?)', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.05)\n",
    "\n",
    "# Add reference lines\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='50% similarity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Steeper drop = model can distinguish closer locations = higher effective resolution\")\n",
    "print(\"- L=40 should show steeper drop at short distances if it has higher resolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Checkerboard Resolution Test (Foundation)\n",
    "\n",
    "Create a synthetic binary classification task where class is determined by a checkerboard pattern.\n",
    "The cell size of the checkerboard determines the required spatial resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkerboard_dataset(cell_size_deg, n_samples=5000, bounds=(-180, 180, -60, 60)):\n",
    "    \"\"\"\n",
    "    Create a checkerboard classification dataset.\n",
    "    \n",
    "    Args:\n",
    "        cell_size_deg: Size of checkerboard cells in degrees\n",
    "        n_samples: Number of samples to generate\n",
    "        bounds: (lon_min, lon_max, lat_min, lat_max)\n",
    "    \n",
    "    Returns:\n",
    "        coords: (N, 2) tensor of [lon, lat]\n",
    "        labels: (N,) tensor of 0/1 labels\n",
    "    \"\"\"\n",
    "    lon_min, lon_max, lat_min, lat_max = bounds\n",
    "    \n",
    "    # Random sample locations\n",
    "    lons = np.random.uniform(lon_min, lon_max, n_samples)\n",
    "    lats = np.random.uniform(lat_min, lat_max, n_samples)\n",
    "    \n",
    "    # Assign labels based on checkerboard pattern\n",
    "    cell_x = (lons / cell_size_deg).astype(int)\n",
    "    cell_y = (lats / cell_size_deg).astype(int)\n",
    "    labels = (cell_x + cell_y) % 2\n",
    "    \n",
    "    coords = torch.tensor(np.stack([lons, lats], axis=1)).double()\n",
    "    labels = torch.tensor(labels).long()\n",
    "    \n",
    "    return coords, labels\n",
    "\n",
    "# Test with different cell sizes\n",
    "# Note: 1 degree latitude ≈ 111 km\n",
    "cell_sizes = [45, 20, 10, 5, 2, 1, 0.5]  # degrees\n",
    "approx_km = [c * 111 for c in cell_sizes]  # approximate km\n",
    "\n",
    "print(\"Cell sizes to test:\")\n",
    "for deg, km in zip(cell_sizes, approx_km):\n",
    "    print(f\"  {deg}° ≈ {km:.0f} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a checkerboard pattern\n",
    "coords_viz, labels_viz = create_checkerboard_dataset(cell_size_deg=20, n_samples=2000)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "scatter = plt.scatter(coords_viz[:, 0], coords_viz[:, 1], c=labels_viz, \n",
    "                      cmap='RdYlBu', s=5, alpha=0.6)\n",
    "plt.colorbar(scatter, label='Class')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Checkerboard Pattern (20° cells ≈ 2200km)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_checkerboard(model, cell_size_deg, n_samples=5000, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluate model's ability to solve checkerboard classification.\n",
    "    \"\"\"\n",
    "    # Create dataset\n",
    "    coords, labels = create_checkerboard_dataset(cell_size_deg, n_samples)\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(coords.to(device)).cpu().numpy()\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        embeddings, labels.numpy(), test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train simple classifier\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Run checkerboard test for both models at different resolutions\n",
    "results_l10 = []\n",
    "results_l40 = []\n",
    "\n",
    "print(\"Running checkerboard resolution test...\\n\")\n",
    "print(f\"{'Cell Size':>12} | {'≈ km':>8} | {'L=10 Acc':>10} | {'L=40 Acc':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for cell_size in cell_sizes:\n",
    "    acc_l10 = evaluate_checkerboard(model_l10, cell_size, n_samples=3000)\n",
    "    acc_l40 = evaluate_checkerboard(model_l40, cell_size, n_samples=3000)\n",
    "    \n",
    "    results_l10.append(acc_l10)\n",
    "    results_l40.append(acc_l40)\n",
    "    \n",
    "    km_approx = cell_size * 111\n",
    "    print(f\"{cell_size:>10.1f}° | {km_approx:>7.0f} | {acc_l10:>10.2%} | {acc_l40:>10.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot checkerboard results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(approx_km, results_l10, 'o-', label='L=10', linewidth=2, markersize=10)\n",
    "plt.plot(approx_km, results_l40, 's-', label='L=40', linewidth=2, markersize=10)\n",
    "\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Random (50%)')\n",
    "plt.axhline(y=0.9, color='green', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Checkerboard Cell Size (km)', fontsize=12)\n",
    "plt.ylabel('Classification Accuracy', fontsize=12)\n",
    "plt.title('Checkerboard Resolution Test\\n(Effective Resolution = where accuracy drops to random)', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0.4, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Where accuracy drops to ~50% = effective resolution limit\")\n",
    "print(\"- L=40 should maintain high accuracy at smaller cell sizes than L=10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModels tested:\")\n",
    "print(f\"  - L=10: {model_l10}\")\n",
    "print(f\"  - L=40: {model_l40}\")\n",
    "\n",
    "print(f\"\\nEmbedding dimension: {emb_l10.shape[1]}\")\n",
    "\n",
    "print(\"\\nKey findings from checkerboard test:\")\n",
    "for i, (cell_size, km, acc10, acc40) in enumerate(zip(cell_sizes, approx_km, results_l10, results_l40)):\n",
    "    diff = acc40 - acc10\n",
    "    better = \"L=40\" if diff > 0.01 else (\"L=10\" if diff < -0.01 else \"~same\")\n",
    "    print(f\"  {km:>6.0f} km cells: L=10={acc10:.1%}, L=40={acc40:.1%} ({better})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "1. Run on finer checkerboard resolutions (0.1°, 0.05°)\n",
    "2. Test with real ecoregion data (Level 1, 2, 3)\n",
    "3. Test with US Census population density data\n",
    "4. Explore intermediate L values if needed\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Model Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters in each model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"L=10 parameters: {count_parameters(model_l10):,}\")\n",
    "print(f\"L=40 parameters: {count_parameters(model_l40):,}\")\n",
    "print(f\"\\nParameter ratio (L=40/L=10): {count_parameters(model_l40)/count_parameters(model_l10):.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
