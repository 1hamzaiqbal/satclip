{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-0",
   "source": "# Extended Analysis: Filling the Gaps\n\nThis notebook addresses remaining questions from experiments 00-07:\n\n## Key Questions\n\n1. **Temperature at Regional Scale**: We showed L=10 wins temperature globally (R²=0.88 vs 0.52).\n   Does L=40 win temperature *within regions* like it does for population?\n\n2. **Raw Spherical Harmonics vs SIREN**: What if we bypass SIREN and use raw SH features?\n   This isolates the contribution of the neural network vs the positional encoding.\n\n3. **Sub-Regional Tests**: Push the regional effect further - test within US states,\n   European countries. Does L=40 advantage increase with smaller regions?\n\n4. **Cross-Region Transfer**: Train on one region, test on another.\n   Does L=40's regional advantage transfer? Tests if L=40 learns general patterns\n   or region-specific features.\n\n## Expected Runtime\n~30-45 minutes on Colab T4 GPU"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-1",
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !rm -rf sample_data .config satclip 2>/dev/null\n",
    "    !git clone https://github.com/1hamzaiqbal/satclip.git\n",
    "    !pip install lightning torchgeo huggingface_hub geopandas shapely requests rasterio --quiet\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    sys.path.append('./satclip/satclip')\n",
    "else:\n",
    "    sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'satclip'))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from huggingface_hub import hf_hub_download\n",
    "from load import get_satclip\n",
    "import positional_encoding as PE\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load models\n",
    "print(\"Loading SatCLIP models...\")\n",
    "model_l10 = get_satclip(hf_hub_download(\"microsoft/SatCLIP-ViT16-L10\", \"satclip-vit16-l10.ckpt\"), device=device)\n",
    "model_l40 = get_satclip(hf_hub_download(\"microsoft/SatCLIP-ViT16-L40\", \"satclip-vit16-l40.ckpt\"), device=device)\n",
    "model_l10.eval()\n",
    "model_l40.eval()\n",
    "\n",
    "# Also get the full geo_model to access raw spherical harmonics\n",
    "full_model_l10 = get_satclip(hf_hub_download(\"microsoft/SatCLIP-ViT16-L10\", \"satclip-vit16-l10.ckpt\"), device=device, return_all=True)\n",
    "full_model_l40 = get_satclip(hf_hub_download(\"microsoft/SatCLIP-ViT16-L40\", \"satclip-vit16-l40.ckpt\"), device=device, return_all=True)\n",
    "\n",
    "print(\"Models loaded!\")\n",
    "\n",
    "def get_embeddings(model, coords, batch_size=1000):\n",
    "    \"\"\"Get SIREN embeddings.\"\"\"\n",
    "    all_emb = []\n",
    "    for i in range(0, len(coords), batch_size):\n",
    "        batch = coords[i:i+batch_size]\n",
    "        coords_tensor = torch.tensor(batch).double()\n",
    "        with torch.no_grad():\n",
    "            emb = model(coords_tensor.to(device)).cpu().numpy()\n",
    "        all_emb.append(emb)\n",
    "    return np.vstack(all_emb)\n",
    "\n",
    "def get_raw_sh_features(coords, L=10):\n",
    "    \"\"\"Get RAW spherical harmonic features (before SIREN).\"\"\"\n",
    "    sh_encoder = PE.SphericalHarmonics(legendre_polys=L)\n",
    "    coords_tensor = torch.tensor(coords).double()\n",
    "    with torch.no_grad():\n",
    "        features = sh_encoder(coords_tensor).cpu().numpy()\n",
    "    return features\n",
    "\n",
    "print(f\"\\nRaw SH feature dimensions:\")\n",
    "print(f\"  L=10: {10*10} = 100 features\")\n",
    "print(f\"  L=40: {40*40} = 1600 features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-2",
   "source": [
    "---\n",
    "## 1. Temperature Prediction: Global vs Regional\n",
    "\n",
    "**Hypothesis**: L=40 will win temperature prediction within regions, just like population.\n",
    "\n",
    "We previously found:\n",
    "- Global temperature: L=10 R²=0.88, L=40 R²=0.52 → L=10 wins big\n",
    "- Global population: L=10 ≈ L=40 (~0.78)\n",
    "- Regional population: L=40 wins by +2% to +8%\n",
    "\n",
    "**Question**: Does L=40 also win regional temperature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-3",
   "outputs": [],
   "source": [
    "# Download temperature data\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "TEMP_URL = \"https://figshare.com/ndownloader/files/41703411\"\n",
    "\n",
    "print(\"Downloading temperature data...\")\n",
    "response = requests.get(TEMP_URL)\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "    z.extractall('./temp_data')\n",
    "\n",
    "# Load the data\n",
    "temp_train = pd.read_csv('./temp_data/train.csv')\n",
    "temp_test = pd.read_csv('./temp_data/test.csv')\n",
    "temp_all = pd.concat([temp_train, temp_test])\n",
    "\n",
    "print(f\"Temperature data: {len(temp_all)} samples\")\n",
    "print(f\"Columns: {temp_all.columns.tolist()}\")\n",
    "print(f\"Lat range: [{temp_all['lat'].min():.1f}, {temp_all['lat'].max():.1f}]\")\n",
    "print(f\"Lon range: [{temp_all['lon'].min():.1f}, {temp_all['lon'].max():.1f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-4",
   "outputs": [],
   "source": [
    "# Define regions for temperature test\n",
    "REGIONS = {\n",
    "    'Global': None,\n",
    "    'North America': (-130, 25, -60, 55),\n",
    "    'Europe': (-10, 35, 40, 70),\n",
    "    'East Asia': (100, 20, 145, 55),\n",
    "    'South America': (-80, -55, -35, 10),\n",
    "    'Africa': (-20, -35, 55, 35),\n",
    "    'Australia': (110, -45, 155, -10),\n",
    "}\n",
    "\n",
    "def filter_by_bounds(df, bounds):\n",
    "    \"\"\"Filter dataframe by geographic bounds.\"\"\"\n",
    "    if bounds is None:\n",
    "        return df\n",
    "    lon_min, lat_min, lon_max, lat_max = bounds\n",
    "    return df[(df['lon'] >= lon_min) & (df['lon'] <= lon_max) &\n",
    "              (df['lat'] >= lat_min) & (df['lat'] <= lat_max)]\n",
    "\n",
    "def run_regression(coords, values, model_l10, model_l40, test_size=0.5, seed=42):\n",
    "    \"\"\"Run regression for both models.\"\"\"\n",
    "    emb_l10 = get_embeddings(model_l10, coords)\n",
    "    emb_l40 = get_embeddings(model_l40, coords)\n",
    "    \n",
    "    X_train_l10, X_test_l10, y_train, y_test = train_test_split(\n",
    "        emb_l10, values, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    X_train_l40, X_test_l40, _, _ = train_test_split(\n",
    "        emb_l40, values, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Scale\n",
    "    scaler_l10, scaler_l40 = StandardScaler(), StandardScaler()\n",
    "    X_train_l10 = scaler_l10.fit_transform(X_train_l10)\n",
    "    X_test_l10 = scaler_l10.transform(X_test_l10)\n",
    "    X_train_l40 = scaler_l40.fit_transform(X_train_l40)\n",
    "    X_test_l40 = scaler_l40.transform(X_test_l40)\n",
    "    \n",
    "    # MLP regression\n",
    "    mlp_l10 = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, random_state=seed, early_stopping=True)\n",
    "    mlp_l40 = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, random_state=seed, early_stopping=True)\n",
    "    \n",
    "    mlp_l10.fit(X_train_l10, y_train)\n",
    "    mlp_l40.fit(X_train_l40, y_train)\n",
    "    \n",
    "    r2_l10 = r2_score(y_test, mlp_l10.predict(X_test_l10))\n",
    "    r2_l40 = r2_score(y_test, mlp_l40.predict(X_test_l40))\n",
    "    \n",
    "    return {'r2_l10': r2_l10, 'r2_l40': r2_l40, 'diff': r2_l40 - r2_l10, 'n': len(coords)}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TEMPERATURE PREDICTION: GLOBAL vs REGIONAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "temp_results = []\n",
    "\n",
    "print(f\"\\n{'Region':<20} | {'N':>7} | {'L=10 R²':>8} | {'L=40 R²':>8} | {'Δ':>8} | Winner\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for region_name, bounds in REGIONS.items():\n",
    "    df = filter_by_bounds(temp_all, bounds)\n",
    "    \n",
    "    if len(df) < 500:\n",
    "        print(f\"{region_name:<20} | Too few samples ({len(df)})\")\n",
    "        continue\n",
    "    \n",
    "    # Sample if too many\n",
    "    if len(df) > 15000:\n",
    "        df = df.sample(n=15000, random_state=42)\n",
    "    \n",
    "    coords = df[['lon', 'lat']].values\n",
    "    values = df['t2m'].values  # Temperature column\n",
    "    \n",
    "    results = run_regression(coords, values, model_l10, model_l40)\n",
    "    winner = \"L=40\" if results['diff'] > 0.02 else (\"L=10\" if results['diff'] < -0.02 else \"~Same\")\n",
    "    \n",
    "    print(f\"{region_name:<20} | {results['n']:>7} | {results['r2_l10']:>8.3f} | {results['r2_l40']:>8.3f} | {results['diff']:>+7.3f} | {winner}\")\n",
    "    \n",
    "    temp_results.append({\n",
    "        'region': region_name,\n",
    "        'n_samples': results['n'],\n",
    "        'r2_l10': results['r2_l10'],\n",
    "        'r2_l40': results['r2_l40'],\n",
    "        'diff': results['diff']\n",
    "    })\n",
    "\n",
    "temp_df = pd.DataFrame(temp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-5",
   "outputs": [],
   "source": [
    "# Compare Temperature vs Population regional effects\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: TEMPERATURE vs POPULATION REGIONAL EFFECTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# From Experiment 07\n",
    "pop_regional = {\n",
    "    'Global': -0.002,\n",
    "    'USA': 0.077,\n",
    "    'Europe': 0.045,\n",
    "    'China': 0.028,\n",
    "    'Africa': 0.037,\n",
    "    'Brazil': 0.035,\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Metric':<25} | {'Population':>12} | {'Temperature':>12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Global\n",
    "global_temp = temp_df[temp_df['region'] == 'Global']['diff'].values[0] if len(temp_df[temp_df['region'] == 'Global']) > 0 else np.nan\n",
    "print(f\"{'Global L=40 advantage':<25} | {pop_regional['Global']:>+11.3f} | {global_temp:>+11.3f}\")\n",
    "\n",
    "# Regional average (excluding global)\n",
    "regional_temp = temp_df[temp_df['region'] != 'Global']['diff'].mean()\n",
    "regional_pop = np.mean([v for k, v in pop_regional.items() if k != 'Global'])\n",
    "print(f\"{'Avg Regional L=40 advantage':<25} | {regional_pop:>+11.3f} | {regional_temp:>+11.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*55)\n",
    "if regional_temp > 0:\n",
    "    print(\"✅ Temperature shows SAME PATTERN as population!\")\n",
    "    print(\"   L=40 wins regionally even for temperature.\")\n",
    "else:\n",
    "    print(\"❌ Temperature does NOT show same pattern.\")\n",
    "    print(\"   L=10 wins temperature at all scales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-6",
   "source": [
    "---\n",
    "## 2. Raw Spherical Harmonics vs SIREN Embeddings\n",
    "\n",
    "**Question**: Is the SIREN network helping or hurting L=40?\n",
    "\n",
    "**Test**: Train MLP directly on raw spherical harmonic features, bypassing SIREN.\n",
    "- L=10: 100 raw features → MLP → prediction\n",
    "- L=40: 1600 raw features → MLP → prediction\n",
    "\n",
    "**Predictions**:\n",
    "- If raw L=40 beats raw L=10: The extra frequencies help\n",
    "- If SIREN L=40 << raw L=40: SIREN is hurting L=40\n",
    "- If SIREN L=40 >> raw L=40: SIREN is helping L=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-7",
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RAW SPHERICAL HARMONICS vs SIREN EMBEDDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use temperature data for this test\n",
    "test_df = temp_all.sample(n=10000, random_state=42)\n",
    "coords = test_df[['lon', 'lat']].values\n",
    "values = test_df['t2m'].values\n",
    "\n",
    "print(\"\\nGetting embeddings and raw features...\")\n",
    "\n",
    "# Get SIREN embeddings\n",
    "emb_siren_l10 = get_embeddings(model_l10, coords)\n",
    "emb_siren_l40 = get_embeddings(model_l40, coords)\n",
    "\n",
    "# Get raw spherical harmonic features\n",
    "sh_raw_l10 = get_raw_sh_features(coords, L=10)\n",
    "sh_raw_l40 = get_raw_sh_features(coords, L=40)\n",
    "\n",
    "print(f\"\\nFeature dimensions:\")\n",
    "print(f\"  SIREN L=10: {emb_siren_l10.shape}\")\n",
    "print(f\"  SIREN L=40: {emb_siren_l40.shape}\")\n",
    "print(f\"  Raw SH L=10: {sh_raw_l10.shape}\")\n",
    "print(f\"  Raw SH L=40: {sh_raw_l40.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-8",
   "outputs": [],
   "source": [
    "def run_regression_with_features(X, y, test_size=0.5, seed=42):\n",
    "    \"\"\"Train MLP regressor on given features.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    mlp = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, random_state=seed, early_stopping=True)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    return r2_score(y_test, mlp.predict(X_test))\n",
    "\n",
    "print(\"\\nTraining regressors on different feature sets...\")\n",
    "\n",
    "# Global temperature regression\n",
    "results_global = {\n",
    "    'SIREN L=10': run_regression_with_features(emb_siren_l10, values),\n",
    "    'SIREN L=40': run_regression_with_features(emb_siren_l40, values),\n",
    "    'Raw SH L=10': run_regression_with_features(sh_raw_l10, values),\n",
    "    'Raw SH L=40': run_regression_with_features(sh_raw_l40, values),\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"GLOBAL Temperature Regression R²\")\n",
    "print(\"-\"*50)\n",
    "for name, r2 in results_global.items():\n",
    "    print(f\"  {name:<15}: {r2:.3f}\")\n",
    "\n",
    "print(\"\\nKey comparisons:\")\n",
    "print(f\"  SIREN helps L=10? {results_global['SIREN L=10'] - results_global['Raw SH L=10']:+.3f}\")\n",
    "print(f\"  SIREN helps L=40? {results_global['SIREN L=40'] - results_global['Raw SH L=40']:+.3f}\")\n",
    "print(f\"  Raw L=40 vs L=10: {results_global['Raw SH L=40'] - results_global['Raw SH L=10']:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-9",
   "outputs": [],
   "source": [
    "# Now test REGIONAL with raw SH features\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RAW SH FEATURES: REGIONAL TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test on Europe only\n",
    "europe_df = filter_by_bounds(temp_all, REGIONS['Europe'])\n",
    "if len(europe_df) > 8000:\n",
    "    europe_df = europe_df.sample(n=8000, random_state=42)\n",
    "\n",
    "coords_eu = europe_df[['lon', 'lat']].values\n",
    "values_eu = europe_df['t2m'].values\n",
    "\n",
    "# Get features for Europe\n",
    "emb_siren_l10_eu = get_embeddings(model_l10, coords_eu)\n",
    "emb_siren_l40_eu = get_embeddings(model_l40, coords_eu)\n",
    "sh_raw_l10_eu = get_raw_sh_features(coords_eu, L=10)\n",
    "sh_raw_l40_eu = get_raw_sh_features(coords_eu, L=40)\n",
    "\n",
    "results_europe = {\n",
    "    'SIREN L=10': run_regression_with_features(emb_siren_l10_eu, values_eu),\n",
    "    'SIREN L=40': run_regression_with_features(emb_siren_l40_eu, values_eu),\n",
    "    'Raw SH L=10': run_regression_with_features(sh_raw_l10_eu, values_eu),\n",
    "    'Raw SH L=40': run_regression_with_features(sh_raw_l40_eu, values_eu),\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"EUROPE Temperature Regression R²\")\n",
    "print(\"-\"*50)\n",
    "for name, r2 in results_europe.items():\n",
    "    print(f\"  {name:<15}: {r2:.3f}\")\n",
    "\n",
    "print(\"\\nKey comparisons (Europe):\")\n",
    "print(f\"  SIREN helps L=10? {results_europe['SIREN L=10'] - results_europe['Raw SH L=10']:+.3f}\")\n",
    "print(f\"  SIREN helps L=40? {results_europe['SIREN L=40'] - results_europe['Raw SH L=40']:+.3f}\")\n",
    "print(f\"  Raw L=40 vs L=10: {results_europe['Raw SH L=40'] - results_europe['Raw SH L=10']:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-10",
   "outputs": [],
   "source": [
    "# Visualize SIREN vs Raw comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Global\n",
    "ax = axes[0]\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, [results_global['Raw SH L=10'], results_global['Raw SH L=40']], width, label='Raw SH', color='steelblue')\n",
    "ax.bar(x + width/2, [results_global['SIREN L=10'], results_global['SIREN L=40']], width, label='SIREN', color='coral')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['L=10', 'L=40'])\n",
    "ax.set_ylabel('R² Score')\n",
    "ax.set_title('Global Temperature: Raw SH vs SIREN')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Europe\n",
    "ax = axes[1]\n",
    "ax.bar(x - width/2, [results_europe['Raw SH L=10'], results_europe['Raw SH L=40']], width, label='Raw SH', color='steelblue')\n",
    "ax.bar(x + width/2, [results_europe['SIREN L=10'], results_europe['SIREN L=40']], width, label='SIREN', color='coral')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['L=10', 'L=40'])\n",
    "ax.set_ylabel('R² Score')\n",
    "ax.set_title('Europe Temperature: Raw SH vs SIREN')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('raw_sh_vs_siren.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\"\"\n",
    "1. Raw SH features alone (no SIREN):\n",
    "   - Global: L=10 R²={results_global['Raw SH L=10']:.3f}, L=40 R²={results_global['Raw SH L=40']:.3f}\n",
    "   - Europe: L=10 R²={results_europe['Raw SH L=10']:.3f}, L=40 R²={results_europe['Raw SH L=40']:.3f}\n",
    "\n",
    "2. Does SIREN help?\n",
    "   - L=10: Global {results_global['SIREN L=10'] - results_global['Raw SH L=10']:+.3f}, Europe {results_europe['SIREN L=10'] - results_europe['Raw SH L=10']:+.3f}\n",
    "   - L=40: Global {results_global['SIREN L=40'] - results_global['Raw SH L=40']:+.3f}, Europe {results_europe['SIREN L=40'] - results_europe['Raw SH L=40']:+.3f}\n",
    "\n",
    "3. Conclusion:\n",
    "\"\"\")\n",
    "if results_global['SIREN L=40'] > results_global['Raw SH L=40']:\n",
    "    print(\"   SIREN HELPS L=40 at global scale\")\n",
    "else:\n",
    "    print(\"   SIREN HURTS L=40 at global scale (raw features work better!)\")\n",
    "\n",
    "if results_europe['Raw SH L=40'] > results_europe['Raw SH L=10']:\n",
    "    print(\"   Raw L=40 features ARE better than L=10 regionally\")\n",
    "else:\n",
    "    print(\"   Raw L=40 features are NOT better than L=10 regionally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-11",
   "source": [
    "---\n",
    "## 3. Sub-Regional Tests: US States & European Countries\n",
    "\n",
    "**Question**: Does L=40 advantage increase with smaller regions?\n",
    "\n",
    "We found:\n",
    "- Continental (~3000km): L=40 +30% advantage\n",
    "- Country (~1000km): Variable results\n",
    "\n",
    "**Test**: Classification within individual US states and European countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-12",
   "outputs": [],
   "source": [
    "# Sub-regional checkerboard test\n",
    "print(\"=\"*70)\n",
    "print(\"SUB-REGIONAL CHECKERBOARD TESTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define sub-regions (US states, EU countries)\n",
    "SUB_REGIONS = {\n",
    "    # US States (approximate bounds)\n",
    "    'California': (-124.5, 32.5, -114, 42),       # ~1000km x 1000km\n",
    "    'Texas': (-106.5, 25.8, -93.5, 36.5),         # ~1300km x 1200km\n",
    "    'Florida': (-87.6, 24.5, -80, 31),            # ~800km x 700km\n",
    "    'New York': (-79.8, 40.5, -71.8, 45.1),       # ~650km x 500km\n",
    "    \n",
    "    # European countries (approximate)\n",
    "    'Germany': (5.9, 47.3, 15.1, 55),             # ~650km x 850km\n",
    "    'France': (-5, 42, 8, 51),                    # ~1000km x 1000km\n",
    "    'Spain': (-9.3, 36, 3.3, 43.8),               # ~1100km x 850km\n",
    "    'Italy': (6.6, 36.6, 18.5, 47.1),             # ~1000km x 1150km\n",
    "    'UK': (-8, 50, 2, 59),                        # ~700km x 1000km\n",
    "}\n",
    "\n",
    "def generate_checkerboard(bounds, cell_size_deg, n_samples=3000, seed=42):\n",
    "    \"\"\"Generate checkerboard classification data within bounds.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    lon_min, lat_min, lon_max, lat_max = bounds\n",
    "    \n",
    "    lons = np.random.uniform(lon_min, lon_max, n_samples)\n",
    "    lats = np.random.uniform(lat_min, lat_max, n_samples)\n",
    "    \n",
    "    # Checkerboard pattern\n",
    "    cell_x = ((lons - lon_min) / cell_size_deg).astype(int)\n",
    "    cell_y = ((lats - lat_min) / cell_size_deg).astype(int)\n",
    "    labels = (cell_x + cell_y) % 2\n",
    "    \n",
    "    coords = np.stack([lons, lats], axis=1)\n",
    "    return coords, labels\n",
    "\n",
    "def run_classification(coords, labels, model_l10, model_l40, test_size=0.5, seed=42):\n",
    "    \"\"\"Run classification with both models.\"\"\"\n",
    "    emb_l10 = get_embeddings(model_l10, coords)\n",
    "    emb_l40 = get_embeddings(model_l40, coords)\n",
    "    \n",
    "    X_train_l10, X_test_l10, y_train, y_test = train_test_split(\n",
    "        emb_l10, labels, test_size=test_size, random_state=seed, stratify=labels\n",
    "    )\n",
    "    X_train_l40, X_test_l40, _, _ = train_test_split(\n",
    "        emb_l40, labels, test_size=test_size, random_state=seed, stratify=labels\n",
    "    )\n",
    "    \n",
    "    clf_l10 = LogisticRegression(max_iter=1000, random_state=seed)\n",
    "    clf_l40 = LogisticRegression(max_iter=1000, random_state=seed)\n",
    "    \n",
    "    clf_l10.fit(X_train_l10, y_train)\n",
    "    clf_l40.fit(X_train_l40, y_train)\n",
    "    \n",
    "    acc_l10 = accuracy_score(y_test, clf_l10.predict(X_test_l10))\n",
    "    acc_l40 = accuracy_score(y_test, clf_l40.predict(X_test_l40))\n",
    "    \n",
    "    return {'acc_l10': acc_l10, 'acc_l40': acc_l40, 'diff': acc_l40 - acc_l10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-13",
   "outputs": [],
   "source": [
    "# Test multiple cell sizes within each sub-region\n",
    "CELL_SIZES = [0.5, 1.0, 2.0, 3.0]  # degrees - corresponds to ~55, 111, 222, 333 km\n",
    "\n",
    "sub_regional_results = []\n",
    "\n",
    "print(f\"\\n{'Region':<12} | {'Size km':<8} | Cell° | {'L=10':>6} | {'L=40':>6} | {'Δ':>7}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for region_name, bounds in SUB_REGIONS.items():\n",
    "    lon_min, lat_min, lon_max, lat_max = bounds\n",
    "    region_size_km = int(((lon_max - lon_min) + (lat_max - lat_min)) / 2 * 111)\n",
    "    \n",
    "    for cell_size in CELL_SIZES:\n",
    "        cell_km = int(cell_size * 111)\n",
    "        \n",
    "        # Skip if cell size is too large for region\n",
    "        if cell_size * 2 > min(lon_max - lon_min, lat_max - lat_min):\n",
    "            continue\n",
    "        \n",
    "        coords, labels = generate_checkerboard(bounds, cell_size)\n",
    "        results = run_classification(coords, labels, model_l10, model_l40)\n",
    "        \n",
    "        print(f\"{region_name:<12} | {region_size_km:>6}km | {cell_size:>4.1f}° | {results['acc_l10']:>5.1%} | {results['acc_l40']:>5.1%} | {results['diff']:>+6.1%}\")\n",
    "        \n",
    "        sub_regional_results.append({\n",
    "            'region': region_name,\n",
    "            'region_size_km': region_size_km,\n",
    "            'cell_size_deg': cell_size,\n",
    "            'cell_size_km': cell_km,\n",
    "            'acc_l10': results['acc_l10'],\n",
    "            'acc_l40': results['acc_l40'],\n",
    "            'diff': results['diff']\n",
    "        })\n",
    "\n",
    "sub_regional_df = pd.DataFrame(sub_regional_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-14",
   "outputs": [],
   "source": [
    "# Summary by cell size\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUB-REGIONAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nAverage L=40 advantage by cell size:\")\n",
    "for cell_size in CELL_SIZES:\n",
    "    cell_data = sub_regional_df[sub_regional_df['cell_size_deg'] == cell_size]\n",
    "    if len(cell_data) > 0:\n",
    "        avg_diff = cell_data['diff'].mean()\n",
    "        print(f\"  {cell_size}° (~{int(cell_size*111)}km): {avg_diff:+.1%}\")\n",
    "\n",
    "print(\"\\nAverage L=40 advantage by region:\")\n",
    "for region in sub_regional_df['region'].unique():\n",
    "    region_data = sub_regional_df[sub_regional_df['region'] == region]\n",
    "    avg_diff = region_data['diff'].mean()\n",
    "    region_size = region_data['region_size_km'].iloc[0]\n",
    "    print(f\"  {region:<12} ({region_size}km): {avg_diff:+.1%}\")\n",
    "\n",
    "# Overall\n",
    "print(f\"\\nOverall average L=40 advantage in sub-regions: {sub_regional_df['diff'].mean():+.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-19",
   "source": [
    "---\n",
    "## 5. Cross-Region Transfer Test\n",
    "\n",
    "**Question**: Does L=40's regional advantage transfer across regions?\n",
    "\n",
    "**Test**: Train on one continent, test on another. If L=40 learns general regional patterns (not region-specific), it should transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-20",
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"CROSS-REGION TRANSFER TEST (EXPANDED)\")\nprint(\"=\"*70)\nprint(\"\"\"\nTesting if L=40's regional advantage transfers across regions.\nIf L=40 learns general local patterns, it should transfer.\nIf L=40's advantage is region-specific, it won't transfer.\n\"\"\")\n\n# PART 1: Temperature regression transfer\nprint(\"-\" * 70)\nprint(\"PART 1: TEMPERATURE REGRESSION TRANSFER\")\nprint(\"-\" * 70)\n\n# More comprehensive transfer pairs\nTRANSFER_PAIRS = [\n    # Europe ↔ Other regions\n    ('Europe', 'North America'),\n    ('Europe', 'East Asia'),\n    ('Europe', 'South America'),\n    ('Europe', 'Africa'),\n    ('Europe', 'Australia'),\n    # North America ↔ Others\n    ('North America', 'Europe'),\n    ('North America', 'East Asia'),\n    ('North America', 'South America'),\n    # East Asia ↔ Others\n    ('East Asia', 'Europe'),\n    ('East Asia', 'North America'),\n    ('East Asia', 'Australia'),\n    # Cross-hemisphere\n    ('South America', 'Africa'),\n    ('Australia', 'South America'),\n]\n\ntransfer_results = []\n\nprint(f\"\\n{'Train':<15} → {'Test':<15} | {'L=10 R²':>8} | {'L=40 R²':>8} | {'Δ':>8} | Winner\")\nprint(\"-\" * 80)\n\nfor train_region, test_region in TRANSFER_PAIRS:\n    train_bounds = REGIONS[train_region]\n    test_bounds = REGIONS[test_region]\n    \n    train_df = filter_by_bounds(temp_all, train_bounds)\n    test_df = filter_by_bounds(temp_all, test_bounds)\n    \n    if len(train_df) < 500 or len(test_df) < 500:\n        print(f\"{train_region:<15} → {test_region:<15} | Too few samples\")\n        continue\n    \n    if len(train_df) > 8000:\n        train_df = train_df.sample(n=8000, random_state=42)\n    if len(test_df) > 4000:\n        test_df = test_df.sample(n=4000, random_state=42)\n    \n    train_coords = train_df[['lon', 'lat']].values\n    train_values = train_df['t2m'].values\n    test_coords = test_df[['lon', 'lat']].values\n    test_values = test_df['t2m'].values\n    \n    emb_train_l10 = get_embeddings(model_l10, train_coords)\n    emb_train_l40 = get_embeddings(model_l40, train_coords)\n    emb_test_l10 = get_embeddings(model_l10, test_coords)\n    emb_test_l40 = get_embeddings(model_l40, test_coords)\n    \n    scaler_l10, scaler_l40 = StandardScaler(), StandardScaler()\n    emb_train_l10 = scaler_l10.fit_transform(emb_train_l10)\n    emb_test_l10 = scaler_l10.transform(emb_test_l10)\n    emb_train_l40 = scaler_l40.fit_transform(emb_train_l40)\n    emb_test_l40 = scaler_l40.transform(emb_test_l40)\n    \n    mlp_l10 = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42, early_stopping=True)\n    mlp_l40 = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42, early_stopping=True)\n    \n    mlp_l10.fit(emb_train_l10, train_values)\n    mlp_l40.fit(emb_train_l40, train_values)\n    \n    r2_l10 = r2_score(test_values, mlp_l10.predict(emb_test_l10))\n    r2_l40 = r2_score(test_values, mlp_l40.predict(emb_test_l40))\n    diff = r2_l40 - r2_l10\n    winner = \"L=40\" if diff > 0.02 else (\"L=10\" if diff < -0.02 else \"~Same\")\n    \n    print(f\"{train_region:<15} → {test_region:<15} | {r2_l10:>8.3f} | {r2_l40:>8.3f} | {diff:>+7.3f} | {winner}\")\n    \n    transfer_results.append({\n        'train': train_region,\n        'test': test_region,\n        'r2_l10': r2_l10,\n        'r2_l40': r2_l40,\n        'diff': diff\n    })\n\ntransfer_df = pd.DataFrame(transfer_results)"
  },
  {
   "cell_type": "code",
   "id": "pytmfv4vaiq",
   "source": "# PART 2: Checkerboard classification transfer\nprint(\"\\n\" + \"-\" * 70)\nprint(\"PART 2: CHECKERBOARD CLASSIFICATION TRANSFER\")\nprint(\"-\" * 70)\nprint(\"\"\"\nTrain a checkerboard classifier on one region, test on another.\nThis tests if the learned spatial discrimination transfers.\n\"\"\")\n\nCHECKER_TRANSFER_PAIRS = [\n    ('Europe', 'North America'),\n    ('Europe', 'East Asia'),\n    ('North America', 'Europe'),\n    ('East Asia', 'Europe'),\n    ('South America', 'Africa'),\n    ('Australia', 'East Asia'),\n]\n\nCELL_SIZE = 2.0  # degrees (~222km)\n\nchecker_transfer_results = []\n\nprint(f\"{'Train':<15} → {'Test':<15} | {'L=10 Acc':>8} | {'L=40 Acc':>8} | {'Δ':>8} | Winner\")\nprint(\"-\" * 80)\n\nfor train_region, test_region in CHECKER_TRANSFER_PAIRS:\n    train_bounds = REGIONS[train_region]\n    test_bounds = REGIONS[test_region]\n    \n    # Generate checkerboard data for both regions\n    train_coords, train_labels = generate_checkerboard(train_bounds, CELL_SIZE, n_samples=4000)\n    test_coords, test_labels = generate_checkerboard(test_bounds, CELL_SIZE, n_samples=2000)\n    \n    # Get embeddings\n    emb_train_l10 = get_embeddings(model_l10, train_coords)\n    emb_train_l40 = get_embeddings(model_l40, train_coords)\n    emb_test_l10 = get_embeddings(model_l10, test_coords)\n    emb_test_l40 = get_embeddings(model_l40, test_coords)\n    \n    # Train classifiers\n    clf_l10 = LogisticRegression(max_iter=1000, random_state=42)\n    clf_l40 = LogisticRegression(max_iter=1000, random_state=42)\n    \n    clf_l10.fit(emb_train_l10, train_labels)\n    clf_l40.fit(emb_train_l40, train_labels)\n    \n    # Test on different region\n    acc_l10 = accuracy_score(test_labels, clf_l10.predict(emb_test_l10))\n    acc_l40 = accuracy_score(test_labels, clf_l40.predict(emb_test_l40))\n    diff = acc_l40 - acc_l10\n    winner = \"L=40\" if diff > 0.02 else (\"L=10\" if diff < -0.02 else \"~Same\")\n    \n    print(f\"{train_region:<15} → {test_region:<15} | {acc_l10:>7.1%} | {acc_l40:>7.1%} | {diff:>+7.1%} | {winner}\")\n    \n    checker_transfer_results.append({\n        'train': train_region,\n        'test': test_region,\n        'acc_l10': acc_l10,\n        'acc_l40': acc_l40,\n        'diff': diff\n    })\n\nchecker_transfer_df = pd.DataFrame(checker_transfer_results)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dumb5y40mxl",
   "source": "# Cross-region transfer summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"CROSS-REGION TRANSFER SUMMARY\")\nprint(\"=\"*70)\n\nprint(\"\\n1. TEMPERATURE REGRESSION TRANSFER:\")\nprint(f\"   Total pairs tested: {len(transfer_df)}\")\nprint(f\"   Average L=40 advantage: {transfer_df['diff'].mean():+.3f}\")\nl40_wins_temp = (transfer_df['diff'] > 0.02).sum()\nl10_wins_temp = (transfer_df['diff'] < -0.02).sum()\nsame_temp = len(transfer_df) - l40_wins_temp - l10_wins_temp\nprint(f\"   L=40 wins: {l40_wins_temp}, L=10 wins: {l10_wins_temp}, Same: {same_temp}\")\n\nprint(\"\\n2. CHECKERBOARD CLASSIFICATION TRANSFER:\")\nprint(f\"   Total pairs tested: {len(checker_transfer_df)}\")\nprint(f\"   Average L=40 advantage: {checker_transfer_df['diff'].mean():+.1%}\")\nl40_wins_check = (checker_transfer_df['diff'] > 0.02).sum()\nl10_wins_check = (checker_transfer_df['diff'] < -0.02).sum()\nsame_check = len(checker_transfer_df) - l40_wins_check - l10_wins_check\nprint(f\"   L=40 wins: {l40_wins_check}, L=10 wins: {l10_wins_check}, Same: {same_check}\")\n\nprint(\"\\n3. INTERPRETATION:\")\nif transfer_df['diff'].mean() > 0 or checker_transfer_df['diff'].mean() > 0:\n    print(\"   ✅ L=40's advantage TRANSFERS to new regions!\")\n    print(\"   This suggests L=40 learns GENERAL local patterns, not region-specific ones.\")\nelse:\n    print(\"   ❌ L=40's advantage does NOT transfer well.\")\n    print(\"   This suggests L=40's advantage may be region-specific.\")\n\n# Visualize\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Temperature transfer\nax = axes[0]\nax.bar(range(len(transfer_df)), transfer_df['diff'], color=['green' if d > 0 else 'red' for d in transfer_df['diff']])\nax.axhline(y=0, color='black', linewidth=1)\nax.set_xticks(range(len(transfer_df)))\nax.set_xticklabels([f\"{t['train']}→{t['test']}\" for _, t in transfer_df.iterrows()], rotation=45, ha='right', fontsize=8)\nax.set_ylabel('L=40 - L=10 R²')\nax.set_title('Temperature Transfer: L=40 Advantage')\nax.grid(True, alpha=0.3, axis='y')\n\n# Checkerboard transfer\nax = axes[1]\nax.bar(range(len(checker_transfer_df)), checker_transfer_df['diff'], color=['green' if d > 0 else 'red' for d in checker_transfer_df['diff']])\nax.axhline(y=0, color='black', linewidth=1)\nax.set_xticks(range(len(checker_transfer_df)))\nax.set_xticklabels([f\"{t['train']}→{t['test']}\" for _, t in checker_transfer_df.iterrows()], rotation=45, ha='right', fontsize=9)\nax.set_ylabel('L=40 - L=10 Accuracy')\nax.set_title('Checkerboard Transfer: L=40 Advantage')\nax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig('cross_region_transfer.png', dpi=150)\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-21",
   "source": [
    "---\n",
    "## 6. Elevation Regression: Regional Test\n",
    "\n",
    "Quick test of another regression task (elevation) to see if regional effect holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-22",
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ELEVATION PROXY: GLOBAL vs REGIONAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use latitude as elevation proxy (very rough - higher latitudes tend to have more varied elevation)\n",
    "# Better: use actual elevation data if available\n",
    "\n",
    "# For now, let's create a synthetic elevation-like target that varies with lat/lon\n",
    "# This is a proxy test - real elevation data would be better\n",
    "\n",
    "def synthetic_elevation(coords):\n",
    "    \"\"\"Synthetic elevation function with regional variation.\"\"\"\n",
    "    lon, lat = coords[:, 0], coords[:, 1]\n",
    "    # Base elevation from latitude (higher = more varied)\n",
    "    base = 1000 + 500 * np.sin(np.radians(lat) * 2)\n",
    "    # Add regional variation\n",
    "    regional = 300 * np.sin(np.radians(lon) * 3) * np.cos(np.radians(lat) * 2)\n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, 100, len(coords))\n",
    "    return base + regional + noise\n",
    "\n",
    "# Test on same regions\n",
    "elev_results = []\n",
    "\n",
    "print(f\"\\n{'Region':<20} | {'N':>7} | {'L=10 R²':>8} | {'L=40 R²':>8} | {'Δ':>8}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for region_name, bounds in REGIONS.items():\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    if bounds is None:\n",
    "        lons = np.random.uniform(-180, 180, 10000)\n",
    "        lats = np.random.uniform(-60, 70, 10000)\n",
    "    else:\n",
    "        lon_min, lat_min, lon_max, lat_max = bounds\n",
    "        lons = np.random.uniform(lon_min, lon_max, 6000)\n",
    "        lats = np.random.uniform(lat_min, lat_max, 6000)\n",
    "    \n",
    "    coords = np.stack([lons, lats], axis=1)\n",
    "    values = synthetic_elevation(coords)\n",
    "    \n",
    "    results = run_regression(coords, values, model_l10, model_l40)\n",
    "    \n",
    "    print(f\"{region_name:<20} | {len(coords):>7} | {results['r2_l10']:>8.3f} | {results['r2_l40']:>8.3f} | {results['diff']:>+7.3f}\")\n",
    "    \n",
    "    elev_results.append({\n",
    "        'region': region_name,\n",
    "        'r2_l10': results['r2_l10'],\n",
    "        'r2_l40': results['r2_l40'],\n",
    "        'diff': results['diff']\n",
    "    })\n",
    "\n",
    "elev_df = pd.DataFrame(elev_results)\n",
    "\n",
    "print(\"\\nNote: This uses SYNTHETIC elevation. Real DEM data would be better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "id": "cell-23",
   "source": [
    "---\n",
    "## Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-24",
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"EXTENDED ANALYSIS SUMMARY\")\nprint(\"=\"*80)\n\nprint(\"\"\"\n1. TEMPERATURE: REGIONAL EFFECT\n\"\"\")\nif len(temp_df) > 0:\n    global_temp_diff = temp_df[temp_df['region'] == 'Global']['diff'].values[0] if 'Global' in temp_df['region'].values else np.nan\n    regional_temp_avg = temp_df[temp_df['region'] != 'Global']['diff'].mean()\n    print(f\"   Global L=40 advantage: {global_temp_diff:+.3f}\")\n    print(f\"   Regional L=40 advantage (avg): {regional_temp_avg:+.3f}\")\n    if regional_temp_avg > global_temp_diff:\n        print(\"   → Temperature CONFIRMS regional effect (like population)!\")\n    else:\n        print(\"   → Temperature does NOT show regional effect.\")\n\nprint(\"\"\"\n2. RAW SPHERICAL HARMONICS vs SIREN\n\"\"\")\nif 'results_global' in dir():\n    print(f\"   Global - Raw L=40 vs L=10: {results_global['Raw SH L=40'] - results_global['Raw SH L=10']:+.3f}\")\n    print(f\"   Global - SIREN helps L=40: {results_global['SIREN L=40'] - results_global['Raw SH L=40']:+.3f}\")\n    if 'results_europe' in dir():\n        print(f\"   Europe - Raw L=40 vs L=10: {results_europe['Raw SH L=40'] - results_europe['Raw SH L=10']:+.3f}\")\n        print(f\"   Europe - SIREN helps L=40: {results_europe['SIREN L=40'] - results_europe['Raw SH L=40']:+.3f}\")\n\nprint(\"\"\"\n3. SUB-REGIONAL TESTS\n\"\"\")\nif len(sub_regional_df) > 0:\n    print(f\"   Average L=40 advantage in US states/EU countries: {sub_regional_df['diff'].mean():+.1%}\")\n    best_region = sub_regional_df.loc[sub_regional_df['diff'].idxmax()]\n    print(f\"   Best: {best_region['region']} at {best_region['cell_size_deg']}° cells: {best_region['diff']:+.1%}\")\n\nprint(\"\"\"\n4. CROSS-REGION TRANSFER (TEMPERATURE)\n\"\"\")\nif len(transfer_df) > 0:\n    print(f\"   Total pairs: {len(transfer_df)}\")\n    print(f\"   Average transfer L=40 advantage: {transfer_df['diff'].mean():+.3f}\")\n    if transfer_df['diff'].mean() > 0:\n        print(\"   → L=40's regression advantage TRANSFERS across regions!\")\n    else:\n        print(\"   → L=40's advantage is region-specific, doesn't transfer well.\")\n\nprint(\"\"\"\n5. CROSS-REGION TRANSFER (CHECKERBOARD)\n\"\"\")\nif 'checker_transfer_df' in dir() and len(checker_transfer_df) > 0:\n    print(f\"   Total pairs: {len(checker_transfer_df)}\")\n    print(f\"   Average transfer L=40 advantage: {checker_transfer_df['diff'].mean():+.1%}\")\n    if checker_transfer_df['diff'].mean() > 0:\n        print(\"   → L=40's classification advantage TRANSFERS across regions!\")\n    else:\n        print(\"   → L=40's advantage is region-specific.\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"KEY TAKEAWAYS\")\nprint(\"=\"*80)\nprint(\"\"\"\n- If temperature shows regional effect: L=40 advantage is NOT task-specific\n- If raw SH L=40 > raw SH L=10: Extra frequencies help even without SIREN\n- If transfer works: L=40 learns general local patterns, not region-specific\n- If transfer fails: L=40's advantage is region-dependent\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "id": "cell-25",
   "outputs": [],
   "source": "# Save all results\nimport json\n\ndef convert_numpy(obj):\n    if isinstance(obj, np.ndarray):\n        return obj.tolist()\n    elif isinstance(obj, (np.integer, np.int64)):\n        return int(obj)\n    elif isinstance(obj, (np.floating, np.float64)):\n        return float(obj)\n    elif isinstance(obj, dict):\n        return {k: convert_numpy(v) for k, v in obj.items()}\n    elif isinstance(obj, list):\n        return [convert_numpy(i) for i in obj]\n    return obj\n\nall_results = {\n    'temperature_regional': convert_numpy(temp_df.to_dict('records')) if len(temp_df) > 0 else [],\n    'raw_sh_global': convert_numpy(results_global) if 'results_global' in dir() else {},\n    'raw_sh_europe': convert_numpy(results_europe) if 'results_europe' in dir() else {},\n    'sub_regional': convert_numpy(sub_regional_df.to_dict('records')) if len(sub_regional_df) > 0 else [],\n    'cross_region_transfer_temp': convert_numpy(transfer_df.to_dict('records')) if len(transfer_df) > 0 else [],\n    'cross_region_transfer_checker': convert_numpy(checker_transfer_df.to_dict('records')) if 'checker_transfer_df' in dir() else [],\n    'elevation_regional': convert_numpy(elev_df.to_dict('records')) if 'elev_df' in dir() else [],\n}\n\nwith open('extended_analysis_results.json', 'w') as f:\n    json.dump(all_results, f, indent=2)\n\nprint(\"✅ Results saved to extended_analysis_results.json\")\nprint(f\"   - Temperature regional: {len(all_results['temperature_regional'])} tests\")\nprint(f\"   - Sub-regional: {len(all_results['sub_regional'])} tests\")\nprint(f\"   - Cross-region transfer (temp): {len(all_results['cross_region_transfer_temp'])} pairs\")\nprint(f\"   - Cross-region transfer (checker): {len(all_results['cross_region_transfer_checker'])} pairs\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}