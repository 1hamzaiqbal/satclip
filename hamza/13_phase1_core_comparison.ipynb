{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Core 2x2 Comparison\n",
    "\n",
    "**Goal**: Establish whether learned activations work at all\n",
    "\n",
    "## The 2x2 Grid\n",
    "\n",
    "| | SIREN | Learned Acts |\n",
    "|---|-------|--------------|\n",
    "| **Raw coords** | Baseline | Test: Can learned acts discover frequencies? |\n",
    "| **SH features** | Baseline | Test: Better nonlinearity than SIREN? |\n",
    "\n",
    "## Key Metrics\n",
    "- R² score\n",
    "- Parameter count  \n",
    "- **Efficiency**: R² per 10K parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    !rm -rf sample_data .config satclip gpw_data 2>/dev/null\n",
    "    !git clone https://github.com/1hamzaiqbal/satclip.git\n",
    "    !pip install lightning torchgeo huggingface_hub rasterio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "GPW_DIR = './gpw_data'\n",
    "os.makedirs(GPW_DIR, exist_ok=True)\n",
    "\n",
    "SOURCE_ZIP_PATH = '/content/drive/MyDrive/grad/learned_activations/dataverse_files.zip'\n",
    "\n",
    "print(\"Extracting GPW data...\")\n",
    "with zipfile.ZipFile(SOURCE_ZIP_PATH, 'r') as z:\n",
    "    z.extractall(GPW_DIR)\n",
    "\n",
    "zip_path = os.path.join(GPW_DIR, 'gpw-v4-population-density-rev11_2020_15_min_tif.zip')\n",
    "if os.path.exists(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(GPW_DIR)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    sys.path.append('./satclip/satclip')\n",
    "else:\n",
    "    sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'satclip'))\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from load import get_satclip\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Load SatCLIP L=10 for SH features\n",
    "print(\"Loading SatCLIP L=10...\")\n",
    "satclip_l10 = get_satclip(hf_hub_download(\"microsoft/SatCLIP-ViT16-L10\", \"satclip-vit16-l10.ckpt\"), device=device)\n",
    "satclip_l10.eval()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Keep it simple for Phase 1\n",
    "# =============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Architecture\n",
    "    'n_layers': 3,\n",
    "    'hidden_dim': 256,\n",
    "    'output_dim': 256,\n",
    "    \n",
    "    # SIREN (matches SatCLIP)\n",
    "    'w0_initial': 30.0,\n",
    "    'w0': 1.0,\n",
    "    \n",
    "    # Learned activations\n",
    "    'n_frequencies': 25,\n",
    "    \n",
    "    # Training\n",
    "    'n_samples': 15000,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 256,\n",
    "    'lr': 1e-3,\n",
    "    \n",
    "    # Spatial blocking\n",
    "    'grid_size': 5.0,\n",
    "    'test_ratio': 0.3,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def load_gpw_raster():\n",
    "    tif_file = f\"{GPW_DIR}/gpw_v4_population_density_rev11_2020_15_min.tif\"\n",
    "    img = Image.open(tif_file)\n",
    "    data = np.array(img)\n",
    "    h, w = data.shape\n",
    "    lons = np.linspace(-180 + 180/w, 180 - 180/w, w)\n",
    "    lats = np.linspace(90 - 90/h, -90 + 90/h, h)\n",
    "    return data, (lons, lats)\n",
    "\n",
    "\n",
    "def sample_with_spatial_blocking(data, coords, cfg, bounds=None, seed=42):\n",
    "    \"\"\"Sample with grid-based spatial blocking.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    lons, lats = coords\n",
    "    valid_mask = data > -1e30\n",
    "    \n",
    "    if bounds:\n",
    "        lon_min, lat_min, lon_max, lat_max = bounds\n",
    "        lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "        valid_mask &= (lon_grid >= lon_min) & (lon_grid <= lon_max)\n",
    "        valid_mask &= (lat_grid >= lat_min) & (lat_grid <= lat_max)\n",
    "    else:\n",
    "        lon_min, lon_max, lat_min, lat_max = -180, 180, -90, 90\n",
    "    \n",
    "    # Grid cells\n",
    "    n_lon = int(np.ceil((lon_max - lon_min) / cfg['grid_size']))\n",
    "    n_lat = int(np.ceil((lat_max - lat_min) / cfg['grid_size']))\n",
    "    n_cells = n_lon * n_lat\n",
    "    \n",
    "    # Assign cells to test\n",
    "    cell_ids = np.arange(n_cells)\n",
    "    np.random.shuffle(cell_ids)\n",
    "    test_cells = set(cell_ids[:int(n_cells * cfg['test_ratio'])])\n",
    "    \n",
    "    # Sample points\n",
    "    valid_idx = np.where(valid_mask)\n",
    "    n_valid = len(valid_idx[0])\n",
    "    sample_idx = np.random.choice(n_valid, min(cfg['n_samples'], n_valid), replace=False)\n",
    "    \n",
    "    rows, cols = valid_idx[0][sample_idx], valid_idx[1][sample_idx]\n",
    "    sample_lons, sample_lats = lons[cols], lats[rows]\n",
    "    sample_vals = data[rows, cols]\n",
    "    \n",
    "    # Split by grid cell\n",
    "    train_mask = []\n",
    "    for lon, lat in zip(sample_lons, sample_lats):\n",
    "        cell = int((lat - lat_min) / cfg['grid_size']) * n_lon + int((lon - lon_min) / cfg['grid_size'])\n",
    "        cell = min(cell, n_cells - 1)\n",
    "        train_mask.append(cell not in test_cells)\n",
    "    train_mask = np.array(train_mask)\n",
    "    \n",
    "    coords_arr = np.stack([sample_lons, sample_lats], axis=1)\n",
    "    \n",
    "    return (\n",
    "        coords_arr[train_mask], sample_vals[train_mask],\n",
    "        coords_arr[~train_mask], sample_vals[~train_mask]\n",
    "    )\n",
    "\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "pop_data, pop_coords = load_gpw_raster()\n",
    "print(f\"Raster shape: {pop_data.shape}\")\n",
    "\n",
    "# Sample with blocking\n",
    "coords_train, vals_train, coords_test, vals_test = sample_with_spatial_blocking(\n",
    "    pop_data, pop_coords, CONFIG\n",
    ")\n",
    "print(f\"Train: {len(coords_train)}, Test: {len(coords_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Definitions (Minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LEARNED ACTIVATION\n",
    "# =============================================================================\n",
    "\n",
    "class LearnedActivation(nn.Module):\n",
    "    \"\"\"Fourier-parameterized activation: g(x) = Σ a_k sin(ω_k x) + b_k cos(ω_k x)\"\"\"\n",
    "    \n",
    "    def __init__(self, n_freq=25, max_freq=10.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer('freqs', torch.linspace(0.1, max_freq, n_freq))\n",
    "        self.sin_c = nn.Parameter(torch.randn(n_freq) * 0.1)\n",
    "        self.cos_c = nn.Parameter(torch.randn(n_freq) * 0.1)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        wx = x.unsqueeze(-1) * self.freqs\n",
    "        out = (torch.sin(wx) * self.sin_c + torch.cos(wx) * self.cos_c).sum(-1)\n",
    "        return self.scale * out + self.bias\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SIREN LAYER (matches SatCLIP)\n",
    "# =============================================================================\n",
    "\n",
    "class SirenLayer(nn.Module):\n",
    "    \"\"\"SIREN layer with proper initialization.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim, w0=1.0, is_first=False):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.w0 = w0\n",
    "        \n",
    "        # SIREN init\n",
    "        with torch.no_grad():\n",
    "            if is_first:\n",
    "                bound = 1.0 / in_dim\n",
    "            else:\n",
    "                bound = math.sqrt(6.0 / in_dim) / w0\n",
    "            self.linear.weight.uniform_(-bound, bound)\n",
    "            self.linear.bias.uniform_(-bound, bound)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.w0 * self.linear(x))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# THE 4 MODELS\n",
    "# =============================================================================\n",
    "\n",
    "class RawSIREN(nn.Module):\n",
    "    \"\"\"Raw coords + SIREN (baseline)\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        h = cfg['hidden_dim']\n",
    "        self.layers = nn.ModuleList([\n",
    "            SirenLayer(2, h, w0=cfg['w0_initial'], is_first=True),\n",
    "            *[SirenLayer(h, h, w0=cfg['w0']) for _ in range(cfg['n_layers'] - 1)]\n",
    "        ])\n",
    "        self.final = nn.Linear(h, cfg['output_dim'])\n",
    "        # SIREN init for final\n",
    "        with torch.no_grad():\n",
    "            b = math.sqrt(6.0 / h) / cfg['w0']\n",
    "            self.final.weight.uniform_(-b, b)\n",
    "            self.final.bias.uniform_(-b, b)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        x = coords / torch.tensor([180., 90.], device=coords.device)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "class RawLearned(nn.Module):\n",
    "    \"\"\"Raw coords + Learned activations (test)\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        h = cfg['hidden_dim']\n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(2, h),\n",
    "            *[nn.Linear(h, h) for _ in range(cfg['n_layers'] - 1)],\n",
    "            nn.Linear(h, cfg['output_dim'])\n",
    "        ])\n",
    "        self.acts = nn.ModuleList([LearnedActivation(cfg['n_frequencies']) for _ in range(cfg['n_layers'])])\n",
    "        \n",
    "        for lin in self.linears:\n",
    "            nn.init.kaiming_normal_(lin.weight)\n",
    "            nn.init.zeros_(lin.bias)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        x = coords / torch.tensor([180., 90.], device=coords.device)\n",
    "        for lin, act in zip(self.linears[:-1], self.acts):\n",
    "            x = act(lin(x))\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class SHSIREN(nn.Module):\n",
    "    \"\"\"SH features + SIREN (baseline, like SatCLIP)\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg, sh_model):\n",
    "        super().__init__()\n",
    "        self.sh_model = sh_model\n",
    "        for p in sh_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Get SH dim\n",
    "        with torch.no_grad():\n",
    "            sh_dim = sh_model.posenc(torch.zeros(1, 2).double().to(next(sh_model.parameters()).device)).shape[-1]\n",
    "        self.sh_dim = sh_dim\n",
    "        \n",
    "        h = cfg['hidden_dim']\n",
    "        self.layers = nn.ModuleList([\n",
    "            SirenLayer(sh_dim, h, w0=cfg['w0_initial'], is_first=True),\n",
    "            *[SirenLayer(h, h, w0=cfg['w0']) for _ in range(cfg['n_layers'] - 1)]\n",
    "        ])\n",
    "        self.final = nn.Linear(h, cfg['output_dim'])\n",
    "        with torch.no_grad():\n",
    "            b = math.sqrt(6.0 / h) / cfg['w0']\n",
    "            self.final.weight.uniform_(-b, b)\n",
    "            self.final.bias.uniform_(-b, b)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        with torch.no_grad():\n",
    "            x = self.sh_model.posenc(coords.double()).float()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "class SHLearned(nn.Module):\n",
    "    \"\"\"SH features + Learned activations (test)\"\"\"\n",
    "    \n",
    "    def __init__(self, cfg, sh_model):\n",
    "        super().__init__()\n",
    "        self.sh_model = sh_model\n",
    "        for p in sh_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sh_dim = sh_model.posenc(torch.zeros(1, 2).double().to(next(sh_model.parameters()).device)).shape[-1]\n",
    "        self.sh_dim = sh_dim\n",
    "        \n",
    "        h = cfg['hidden_dim']\n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(sh_dim, h),\n",
    "            *[nn.Linear(h, h) for _ in range(cfg['n_layers'] - 1)],\n",
    "            nn.Linear(h, cfg['output_dim'])\n",
    "        ])\n",
    "        self.acts = nn.ModuleList([LearnedActivation(cfg['n_frequencies']) for _ in range(cfg['n_layers'])])\n",
    "        \n",
    "        for lin in self.linears:\n",
    "            nn.init.kaiming_normal_(lin.weight)\n",
    "            nn.init.zeros_(lin.bias)\n",
    "    \n",
    "    def forward(self, coords):\n",
    "        with torch.no_grad():\n",
    "            x = self.sh_model.posenc(coords.double()).float()\n",
    "        for lin, act in zip(self.linears[:-1], self.acts):\n",
    "            x = act(lin(x))\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "# Print param counts\n",
    "print(\"\\nParameter counts:\")\n",
    "for name, cls in [('RawSIREN', RawSIREN), ('RawLearned', RawLearned)]:\n",
    "    m = cls(CONFIG)\n",
    "    print(f\"  {name}: {sum(p.numel() for p in m.parameters()):,}\")\n",
    "\n",
    "for name, cls in [('SHSIREN', SHSIREN), ('SHLearned', SHLearned)]:\n",
    "    m = cls(CONFIG, satclip_l10)\n",
    "    print(f\"  {name} (SH dim={m.sh_dim}): {sum(p.numel() for p in m.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    \"\"\"Encoder + prediction head.\"\"\"\n",
    "    def __init__(self, encoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.head(self.encoder(x)).squeeze(-1)\n",
    "\n",
    "\n",
    "def train_and_eval(encoder, coords_train, vals_train, coords_test, vals_test, cfg):\n",
    "    \"\"\"Train encoder and return metrics.\"\"\"\n",
    "    model = Predictor(encoder).to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=cfg['lr'])\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    # Data\n",
    "    train_X = torch.tensor(coords_train, dtype=torch.float32)\n",
    "    train_y = torch.tensor(np.log1p(vals_train), dtype=torch.float32)\n",
    "    test_X = torch.tensor(coords_test, dtype=torch.float32).to(device)\n",
    "    test_y = torch.tensor(np.log1p(vals_test), dtype=torch.float32)\n",
    "    \n",
    "    loader = DataLoader(TensorDataset(train_X, train_y), batch_size=cfg['batch_size'], shuffle=True)\n",
    "    \n",
    "    start = time.time()\n",
    "    best_r2 = -float('inf')\n",
    "    \n",
    "    for epoch in range(cfg['epochs']):\n",
    "        model.train()\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss_fn(model(X), y).backward()\n",
    "            opt.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model(test_X).cpu().numpy()\n",
    "        r2 = r2_score(test_y.numpy(), pred)\n",
    "        best_r2 = max(best_r2, r2)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"    Epoch {epoch+1}: R²={r2:.4f}\")\n",
    "    \n",
    "    train_time = time.time() - start\n",
    "    n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    return {\n",
    "        'r2': best_r2,\n",
    "        'params': n_params,\n",
    "        'efficiency': best_r2 / (n_params / 10000),\n",
    "        'time': train_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run the 2x2 Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PHASE 1: Core 2x2 Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = []\n",
    "\n",
    "# 1. Raw + SIREN\n",
    "print(\"\\n[1/4] Raw + SIREN (baseline)...\")\n",
    "encoder = RawSIREN(CONFIG)\n",
    "res = train_and_eval(encoder, coords_train, vals_train, coords_test, vals_test, CONFIG)\n",
    "res['model'] = 'Raw + SIREN'\n",
    "res['encoding'] = 'Raw'\n",
    "res['activation'] = 'SIREN'\n",
    "results.append(res)\n",
    "print(f\"    -> R²={res['r2']:.4f}, Params={res['params']:,}, Efficiency={res['efficiency']:.4f}\")\n",
    "\n",
    "# 2. Raw + Learned\n",
    "print(\"\\n[2/4] Raw + Learned (test)...\")\n",
    "encoder = RawLearned(CONFIG)\n",
    "res = train_and_eval(encoder, coords_train, vals_train, coords_test, vals_test, CONFIG)\n",
    "res['model'] = 'Raw + Learned'\n",
    "res['encoding'] = 'Raw'\n",
    "res['activation'] = 'Learned'\n",
    "results.append(res)\n",
    "print(f\"    -> R²={res['r2']:.4f}, Params={res['params']:,}, Efficiency={res['efficiency']:.4f}\")\n",
    "\n",
    "# 3. SH + SIREN\n",
    "print(\"\\n[3/4] SH + SIREN (baseline)...\")\n",
    "encoder = SHSIREN(CONFIG, satclip_l10)\n",
    "res = train_and_eval(encoder, coords_train, vals_train, coords_test, vals_test, CONFIG)\n",
    "res['model'] = 'SH + SIREN'\n",
    "res['encoding'] = 'SH(L=10)'\n",
    "res['activation'] = 'SIREN'\n",
    "results.append(res)\n",
    "print(f\"    -> R²={res['r2']:.4f}, Params={res['params']:,}, Efficiency={res['efficiency']:.4f}\")\n",
    "\n",
    "# 4. SH + Learned\n",
    "print(\"\\n[4/4] SH + Learned (test)...\")\n",
    "encoder = SHLearned(CONFIG, satclip_l10)\n",
    "res = train_and_eval(encoder, coords_train, vals_train, coords_test, vals_test, CONFIG)\n",
    "res['model'] = 'SH + Learned'\n",
    "res['encoding'] = 'SH(L=10)'\n",
    "res['activation'] = 'Learned'\n",
    "results.append(res)\n",
    "print(f\"    -> R²={res['r2']:.4f}, Params={res['params']:,}, Efficiency={res['efficiency']:.4f}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Format as 2x2 table\n",
    "print(\"\\n--- R² Scores ---\")\n",
    "pivot_r2 = df.pivot(index='encoding', columns='activation', values='r2')\n",
    "print(pivot_r2.round(4).to_string())\n",
    "\n",
    "print(\"\\n--- Efficiency (R² per 10K params) ---\")\n",
    "pivot_eff = df.pivot(index='encoding', columns='activation', values='efficiency')\n",
    "print(pivot_eff.round(4).to_string())\n",
    "\n",
    "print(\"\\n--- Full Results ---\")\n",
    "print(df[['model', 'r2', 'params', 'efficiency', 'time']].round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# R² comparison\n",
    "ax = axes[0]\n",
    "x = np.arange(2)\n",
    "w = 0.35\n",
    "siren_r2 = [df[df['model'] == 'Raw + SIREN']['r2'].values[0],\n",
    "            df[df['model'] == 'SH + SIREN']['r2'].values[0]]\n",
    "learned_r2 = [df[df['model'] == 'Raw + Learned']['r2'].values[0],\n",
    "              df[df['model'] == 'SH + Learned']['r2'].values[0]]\n",
    "ax.bar(x - w/2, siren_r2, w, label='SIREN', color='steelblue')\n",
    "ax.bar(x + w/2, learned_r2, w, label='Learned', color='coral')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Raw coords', 'SH(L=10)'])\n",
    "ax.set_ylabel('R² Score')\n",
    "ax.set_title('Performance Comparison')\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Efficiency comparison\n",
    "ax = axes[1]\n",
    "siren_eff = [df[df['model'] == 'Raw + SIREN']['efficiency'].values[0],\n",
    "             df[df['model'] == 'SH + SIREN']['efficiency'].values[0]]\n",
    "learned_eff = [df[df['model'] == 'Raw + Learned']['efficiency'].values[0],\n",
    "               df[df['model'] == 'SH + Learned']['efficiency'].values[0]]\n",
    "ax.bar(x - w/2, siren_eff, w, label='SIREN', color='steelblue')\n",
    "ax.bar(x + w/2, learned_eff, w, label='Learned', color='coral')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Raw coords', 'SH(L=10)'])\n",
    "ax.set_ylabel('Efficiency (R² / 10K params)')\n",
    "ax.set_title('Parameter Efficiency')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('phase1_results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key findings\n",
    "print(\"=\"*70)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "raw_siren = df[df['model'] == 'Raw + SIREN'].iloc[0]\n",
    "raw_learned = df[df['model'] == 'Raw + Learned'].iloc[0]\n",
    "sh_siren = df[df['model'] == 'SH + SIREN'].iloc[0]\n",
    "sh_learned = df[df['model'] == 'SH + Learned'].iloc[0]\n",
    "\n",
    "print(\"\\n1. Can learned activations discover frequencies (Raw coords)?\")\n",
    "diff = raw_learned['r2'] - raw_siren['r2']\n",
    "if diff > 0.01:\n",
    "    print(f\"   YES! Learned ({raw_learned['r2']:.3f}) > SIREN ({raw_siren['r2']:.3f}) by {diff:+.3f}\")\n",
    "elif diff < -0.01:\n",
    "    print(f\"   NO. SIREN ({raw_siren['r2']:.3f}) > Learned ({raw_learned['r2']:.3f}) by {-diff:.3f}\")\n",
    "else:\n",
    "    print(f\"   SIMILAR. SIREN={raw_siren['r2']:.3f}, Learned={raw_learned['r2']:.3f}\")\n",
    "\n",
    "print(\"\\n2. Are learned activations a better nonlinearity than SIREN (with SH)?\")\n",
    "diff = sh_learned['r2'] - sh_siren['r2']\n",
    "if diff > 0.01:\n",
    "    print(f\"   YES! Learned ({sh_learned['r2']:.3f}) > SIREN ({sh_siren['r2']:.3f}) by {diff:+.3f}\")\n",
    "elif diff < -0.01:\n",
    "    print(f\"   NO. SIREN ({sh_siren['r2']:.3f}) > Learned ({sh_learned['r2']:.3f}) by {-diff:.3f}\")\n",
    "else:\n",
    "    print(f\"   SIMILAR. SIREN={sh_siren['r2']:.3f}, Learned={sh_learned['r2']:.3f}\")\n",
    "\n",
    "print(\"\\n3. Does SH encoding help?\")\n",
    "best_raw = max(raw_siren['r2'], raw_learned['r2'])\n",
    "best_sh = max(sh_siren['r2'], sh_learned['r2'])\n",
    "print(f\"   Best Raw: {best_raw:.3f}, Best SH: {best_sh:.3f} ({best_sh - best_raw:+.3f})\")\n",
    "\n",
    "print(\"\\n4. Parameter efficiency winner:\")\n",
    "best_eff = df.loc[df['efficiency'].idxmax()]\n",
    "print(f\"   {best_eff['model']}: {best_eff['efficiency']:.4f} R²/10K params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "df.to_csv('phase1_results.csv', index=False)\n",
    "print(\"Results saved to phase1_results.csv\")\n",
    "\n",
    "# Next steps\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "Based on these results:\n",
    "\n",
    "If Learned ≈ SIREN on Raw coords:\n",
    "  -> Learned activations CAN discover frequencies\n",
    "  -> Proceed to Phase 2: Try different activation types (splines, etc.)\n",
    "\n",
    "If Learned < SIREN on Raw coords:\n",
    "  -> May need more frequencies or different architecture\n",
    "  -> Focus on SH + Learned path\n",
    "\n",
    "If SH + Learned > SH + SIREN:\n",
    "  -> Better nonlinearity confirmed!\n",
    "  -> This is the promising path for improvement\n",
    "\n",
    "See EXPERIMENT_ROADMAP.md for full plan.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
